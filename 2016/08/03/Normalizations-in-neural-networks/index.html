<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Normalizations in neural networks | yeephycho</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Normalizations for the input data (normalization, equalization)In image process area, the term “normalization)” has many other names such as contrast stretching, histogram stretching or dynamic range">
<meta property="og:type" content="article">
<meta property="og:title" content="Normalizations in neural networks">
<meta property="og:url" content="http://yeephycho.github.io/2016/08/03/Normalizations-in-neural-networks/index.html">
<meta property="og:site_name" content="yeephycho">
<meta property="og:description" content="Normalizations for the input data (normalization, equalization)In image process area, the term “normalization)” has many other names such as contrast stretching, histogram stretching or dynamic range">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/normalization.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/yeephycho/yeephycho.github.io/master/blog_img/CC_BY.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yeephycho/yeephycho.github.io/master/blog_img/APACHE.png">
<meta property="og:updated_time" content="2016-08-11T03:46:20.670Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Normalizations in neural networks">
<meta name="twitter:description" content="Normalizations for the input data (normalization, equalization)In image process area, the term “normalization)” has many other names such as contrast stretching, histogram stretching or dynamic range">
<meta name="twitter:image" content="http://yeephycho.github.io/blog_img/normalization.jpg">
  
    <link rel="alternative" href="/atom.xml" title="yeephycho" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://yeephycho.github.io/blog_img/zombie2.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">yeephycho</a></h1>
		</hgroup>

		
		<p class="header-subtitle">Possibly, yeephycho is a phycho.</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						
						<li>About</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/yeephycho.github.io">Home Page</a></li>
				        
							<li><a href="/archives">All article</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/yeephycho" title="github">github</a>
					        
								<a class="linkedin" target="_blank" href="https://www.linkedin.com/in/%E4%BB%A5%E7%92%87-%E8%83%A1-82ab00102" title="linkedin">linkedin</a>
					        
								<a class="facebook" target="_blank" href="https://www.facebook.com/profile.php?id=100004383827370" title="facebook">facebook</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/AlexNet/" style="font-size: 10px;">AlexNet</a> <a href="/tags/Author/" style="font-size: 10px;">Author</a> <a href="/tags/BN-Inception/" style="font-size: 10px;">BN-Inception</a> <a href="/tags/Batch-Normalization/" style="font-size: 10px;">Batch Normalization</a> <a href="/tags/Blog/" style="font-size: 10px;">Blog</a> <a href="/tags/CUDA/" style="font-size: 10px;">CUDA</a> <a href="/tags/Convolutional-Neural-Network/" style="font-size: 20px;">Convolutional Neural Network</a> <a href="/tags/GoogLeNet/" style="font-size: 10px;">GoogLeNet</a> <a href="/tags/Histogram-equalization/" style="font-size: 10px;">Histogram equalization</a> <a href="/tags/Inception-module/" style="font-size: 10px;">Inception module</a> <a href="/tags/Inception-v3/" style="font-size: 10px;">Inception-v3</a> <a href="/tags/Julia-set/" style="font-size: 10px;">Julia set</a> <a href="/tags/LeNet-5/" style="font-size: 10px;">LeNet-5</a> <a href="/tags/License/" style="font-size: 10px;">License</a> <a href="/tags/Local-Contrast-Normalization/" style="font-size: 10px;">Local Contrast Normalization</a> <a href="/tags/Local-Response-Normalization/" style="font-size: 10px;">Local Response Normalization</a> <a href="/tags/Network-Structures/" style="font-size: 10px;">Network Structures</a> <a href="/tags/Normalization-Algorithms/" style="font-size: 10px;">Normalization Algorithms</a> <a href="/tags/OpenCL/" style="font-size: 10px;">OpenCL</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/OpenMP/" style="font-size: 10px;">OpenMP</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">Currently work for TCL Corporate Research Hong Kong Co., Ltd. Interested in high performance computing and machine learning.</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">yeephycho</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="http://yeephycho.github.io/blog_img/zombie2.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">yeephycho</h1>
			</hgroup>
			
			<p class="header-subtitle">Possibly, yeephycho is a phycho.</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/yeephycho.github.io">Home Page</a></li>
		        
					<li><a href="/archives">All article</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/yeephycho" title="github">github</a>
			        
						<a class="linkedin" target="_blank" href="https://www.linkedin.com/in/%E4%BB%A5%E7%92%87-%E8%83%A1-82ab00102" title="linkedin">linkedin</a>
			        
						<a class="facebook" target="_blank" href="https://www.facebook.com/profile.php?id=100004383827370" title="facebook">facebook</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="title-Normalizations-in-neural-networks" class="article article-type-title" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/08/03/Normalizations-in-neural-networks/" class="article-date">
  	<time datetime="2016-08-03T12:10:48.000Z" itemprop="datePublished">2016-08-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Normalizations in neural networks
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Batch-Normalization/">Batch Normalization</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Convolutional-Neural-Network/">Convolutional Neural Network</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Histogram-equalization/">Histogram equalization</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Local-Contrast-Normalization/">Local Contrast Normalization</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Local-Response-Normalization/">Local Response Normalization</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Normalization-Algorithms/">Normalization Algorithms</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Normalizations-for-the-input-data-normalization-equalization"><a href="#Normalizations-for-the-input-data-normalization-equalization" class="headerlink" title="Normalizations for the input data (normalization, equalization)"></a>Normalizations for the input data (normalization, equalization)</h2><p>In image process area, the term “<a href="https://en.wikipedia.org/wiki/Normalization_(image_processing" target="_blank" rel="external">normalization</a>)” has many other names such as contrast stretching, histogram stretching or dynamic range expansion etc.<br>If you have an 8-bit grayscale image, the minimum and maximum pixel values are 50 and 180, we can normalize this image to a larger dynamic range say 0 to 255. After normalize, the pervious 50 becomes 0, and 180 becomes 255, the values in the middle will be scaled according to the following formula:<div align="center"><br><strong>(I_n: new_intensity) = ((I_o: old_intensity)- (I_o_min: old_minimum_intensity)) x ((I_n_max: new_maximum_intensity) - (I_n_min: new_minimum_intensity)) / ((I_o_max: old_maximum_intensity) - (I_o_min: old_minimum_intensity)) + (I_n_min: new_minimum_intensity)</strong><br><br><br><img src="http://yeephycho.github.io/blog_img/normalization.jpg" alt="Normalization"><br></div><br><a id="more"></a><br>It’s a typical linear transform. Still the previous image, the pixel value 70 will become (70-50)x(255-0)/(180-50) - 0 = 39, the pixel value 130 will become (130-50)x(255-0)/(180-50) - 0 = 156.<br>The image below shows a image before and after normalization, the third image is effect of another transform called <a href="https://en.wikipedia.org/wiki/Histogram_equalization" target="_blank" rel="external">histogram equalization</a>, for your information, histogram equalization is different from normalization, normalization will not change your image’s histogram but equalization will. Histogram equalization doesn’t care about intensity value of the pixel, however, the ranking of the current intensity in the whole image matters a lot.<br>The maximum intensity of the orginial image is 238 and the minimum is 70, implememtated through OpenCV. (OpenCV’s normalization function isn’t the normalization we are talking about, if you want to repeat the effect, you have to do it yourself.)<br>For normalization, the new intensity derives from the new and old maximum, minimum intensity; for equalization, the new intensity derives from the intensity value’s ranking in the whole image (for example, a image has 64 pixels, the intensity of a certain pixel is 90, and there are 22 pixels has a low intensity and 41 pixels has a higher intensity, the new intensity after equalization of that point is (22/64) x (255-0) = 87). </p>
<h2 id="Principle-Component-Analysis-PCA-and-Whitening"><a href="#Principle-Component-Analysis-PCA-and-Whitening" class="headerlink" title="Principle Component Analysis (PCA) and Whitening"></a>Principle Component Analysis (PCA) and Whitening</h2><p>TBC…</p>
<h2 id="Local-Constrast-Normalization-LCN"><a href="#Local-Constrast-Normalization-LCN" class="headerlink" title="Local Constrast Normalization (LCN)"></a>Local Constrast Normalization (LCN)</h2><p>Related papers are listed below:<br><a href="http://journals.plos.org/ploscompbiol/article?id=10.1371%2Fjournal.pcbi.0040027" target="_blank" rel="external">Why is Real-World Visual Object Recognition Hard?</a>, published in Jan. 2008. At this time, the name is “Local input divisive normalization”.<br><a href="http://www.cns.nyu.edu/pub/lcv/lyu08b.pdf" target="_blank" rel="external">Nonlinear Image Representation Using Divisive Normalization</a>, published in Jun. 2008. The name is “Divisive Normalization”.<br><a href="http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf" target="_blank" rel="external">What is the Best Multi-Stage Architecture for Object Recognition?</a>, released in 2009. The name is “Local Constrast Normalization”.<br>Whitening is a way to normalise the data in different dimensions to reduce the correlations among the data, however, local contrast normalization, whose idea is inspired by computational neuroscience, aims at to make the features in feature maps more significant.<br><blockquote><p>This (Local Constrast Normalization) module performas local subtractive and divisive normalizations, enforcing a sort of local competition between adjacent features in a feature map, and between features at the same spatial location in different feature maps.</p>
</blockquote><br>Local contrast normalization is implemented as follows:<br>    First, for each pixel in a feature map, find its adjacent pixels. Let’s say the radius is 1, so there are 8 pixels around the target pixel (do the zero padding if the target is at the edge of the feature map).<br>    Then, compute the mean of these 9 pixels (8 neighbour pixels and the target pixel itself), subtract the mean for each one of the 9 pixels.<br>    Next, compute the standard variance of these 9 pixels. And judge whether the standard variance is larger then 1. If larger than 1, divide the target pixel’s value (after mean subtraction) by the standard variance. If not larger, keep the target’s value as they what they are (after mean subtraction).<br>    At last, save the target pixel value to the same spatial position of a blank feature map as the input of the following CNN stages.<br>I typed the following python code to illustrate the math of the LCN:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.matrix(np.random.randint(<span class="number">0</span>,<span class="number">255</span>, size=(<span class="number">3</span>, <span class="number">3</span>))) <span class="comment"># generate a random 3x3 matrix, the pixel value is ranging from 0 to 255.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">matrix([[<span class="number">201</span>, <span class="number">239</span>, <span class="number">77</span>], [<span class="number">139</span>, <span class="number">157</span>, <span class="number">23</span>], [<span class="number">235</span>, <span class="number">207</span>, <span class="number">173</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mean = np.mean(x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mean</span><br><span class="line"><span class="number">161.2222222222223</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = x - mean</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">matrix([[<span class="number">39.77777778</span>, <span class="number">77.77777778</span>, <span class="number">-84.22222222</span>], [<span class="number">-22.22222222</span>, <span class="number">-4.22222222</span>, <span class="number">-138.22222222</span>], [<span class="number">73.77777778</span>, <span class="number">45.77777778</span>, <span class="number">11.77777778</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>std_var = np.sqrt(np.var(x)）</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>std_var</span><br><span class="line"><span class="number">68.328906</span>...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>std_var &gt; <span class="number">1</span></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>LCN_value = x[(<span class="number">1</span>, <span class="number">1</span>)]/std_var</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>LCN_value</span><br><span class="line"><span class="number">-0.0617926207</span>...</span><br></pre></td></tr></table></figure></p>
<p>Please be noted that the real process in the neural network is not looks like this, because the data is usually whitened before feed to the network, the image usually isn’t randomly generated and the negative value is usually set to zero in ReLU.<br>Here, we presume that each adjacent pixel has the same importance to the contrast normalization so we calculate the mean of the 9 pixels, actually, the weights for each pixel can be various.<br>We, presume the adjacent pixel radius is 1 and the image has only one channel, but the radius can be larger or smaller, you can pick up 4 adjacent pixels (up, down, left, right) or 24 pixels (radius is 2) or arbitrary pixels at arbitrary positions (the result may looks odd).<br>In the third paper, they introduced the divisive normalization into neural networks, and there is variation, that is the contrast normalization among adjacent feature maps at the same spatial position (say a pixel select two adjacent feature maps, the neighbour pixel number is 3x3x3 - 1). In conv. neural network, the output of a layer may have may feature maps, and the LCN can enhance feature presentations in some feature maps at the mean time restrain the presentations in other feature maps. </p>
<h2 id="Local-Response-Normalization"><a href="#Local-Response-Normalization" class="headerlink" title="Local Response Normalization"></a>Local Response Normalization</h2><p>This concept was raised in AlexNet, click <a href="http://yeephycho.github.io/2016/07/21/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-I/">here</a> to learn more.<br>Local response normalization, for my understanding, is naturally different from all the other normalizations here. The reason is that for the other normalizations, the target is to normalise the data, but local contrast normalization is actually working on models (conv. kernels at the same layer).</p>
<p>TBC…</p>
<h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>I summarized related paper in <a href="http://yeephycho.github.io/2016/08/02/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-II/">another blog</a>.<br>Batch normalization, at first glance, is quite difficult to understand, and it truly introduced something new to CNNs, that is a kind of learnable whitening process to the inputs of the non-linear activations(ReLUs or Sigmoids).<br>TBC..</p>
<p><br></p>
<h2 id="License"><a href="#License" class="headerlink" title="License"></a>License</h2><div align="center"><br>The content of this blog itself is licensed under the <a href="http://creativecommons.org/licenses/by/4.0/" target="_blank" rel="external">Creative Commons Attribution 4.0 International License</a>.<br><img src="https://raw.githubusercontent.com/yeephycho/yeephycho.github.io/master/blog_img/CC_BY.png" class="[CC_BY_LICENSE]" title="[88] [31] [CC_BY 4.0 [CC_BY 4.0]]"><br><br>The containing source code (if applicable) and the source code used to format and display that content is licensed under the <a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank" rel="external">Apache License 2.0</a>.<br><strong>Copyright [2016] [yeephycho]</strong><br>Licensed under the Apache License, Version 2.0 (the “License”);<br>you may not use this file except in compliance with the License.<br>You may obtain a copy of the License at<br><a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank" rel="external">Apache License 2.0</a><br>Unless required by applicable law or agreed to in writing, software<br>distributed under the License is distributed on an “AS IS” BASIS,<br>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either<br>express or implied. See the License for the specific language<br>governing permissions and limitations under the License.<br><img src="https://raw.githubusercontent.com/yeephycho/yeephycho.github.io/master/blog_img/APACHE.png" class="[APACHE_LICENSE]" title="[120] [48] [APACHE_LICENSE 2.0 [APACHE_LICENSE 2.0]]"><br></div>
      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2090/06/07/my_first_blog/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Welcome to yeephycho&#39;s blog
        
      </div>
    </a>
  
  
    <a href="/2016/08/02/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-II/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">A note to techniques in Convolutional Neural Networks and their influences II (paper summary)</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>








<section id="comments">
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'yeephycho'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>

</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 yeephycho
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: true
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>



<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-79750926-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
  <script id="dsq-count-scr" src="//yeephycho.disqus.com/count.js#disqus_thread" async></script>
</body>
</html>