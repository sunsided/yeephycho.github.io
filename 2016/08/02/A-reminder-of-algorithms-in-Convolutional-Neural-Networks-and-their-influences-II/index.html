<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>A note to techniques in Convolutional Neural Networks and their influences II (paper summary) | yeephycho</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="If you are not quite familiar with CNN, please view my previous blog for a better understanding.
BN-InceptionRelated paper is: Batch Normalization: Accelerating Deep Network Training by Reducing Inter">
<meta property="og:type" content="article">
<meta property="og:title" content="A note to techniques in Convolutional Neural Networks and their influences II (paper summary)">
<meta property="og:url" content="http://yeephycho.github.io/2016/08/02/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-II/index.html">
<meta property="og:site_name" content="yeephycho">
<meta property="og:description" content="If you are not quite familiar with CNN, please view my previous blog for a better understanding.
BN-InceptionRelated paper is: Batch Normalization: Accelerating Deep Network Training by Reducing Inter">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/BN_Inception.JPG">
<meta property="og:image" content="https://raw.githubusercontent.com/yeephycho/yeephycho.github.io/master/blog_img/CC_BY.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yeephycho/yeephycho.github.io/master/blog_img/APACHE.png">
<meta property="og:updated_time" content="2016-08-09T03:29:28.962Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A note to techniques in Convolutional Neural Networks and their influences II (paper summary)">
<meta name="twitter:description" content="If you are not quite familiar with CNN, please view my previous blog for a better understanding.
BN-InceptionRelated paper is: Batch Normalization: Accelerating Deep Network Training by Reducing Inter">
<meta name="twitter:image" content="http://yeephycho.github.io/blog_img/BN_Inception.JPG">
  
    <link rel="alternative" href="/atom.xml" title="yeephycho" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://yeephycho.github.io/blog_img/zombie2.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">yeephycho</a></h1>
		</hgroup>

		
		<p class="header-subtitle">Possibly, yeephycho is a phycho.</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						
						<li>About</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/yeephycho.github.io">Home Page</a></li>
				        
							<li><a href="/archives">All article</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/yeephycho" title="github">github</a>
					        
								<a class="linkedin" target="_blank" href="https://www.linkedin.com/in/%E4%BB%A5%E7%92%87-%E8%83%A1-82ab00102" title="linkedin">linkedin</a>
					        
								<a class="facebook" target="_blank" href="https://www.facebook.com/profile.php?id=100004383827370" title="facebook">facebook</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/AlexNet/" style="font-size: 10px;">AlexNet</a> <a href="/tags/Author/" style="font-size: 10px;">Author</a> <a href="/tags/BN-Inception/" style="font-size: 10px;">BN-Inception</a> <a href="/tags/Batch-Normalization/" style="font-size: 10px;">Batch Normalization</a> <a href="/tags/Blog/" style="font-size: 10px;">Blog</a> <a href="/tags/CUDA/" style="font-size: 10px;">CUDA</a> <a href="/tags/Convolutional-Neural-Network/" style="font-size: 20px;">Convolutional Neural Network</a> <a href="/tags/GoogLeNet/" style="font-size: 10px;">GoogLeNet</a> <a href="/tags/Histogram-equalization/" style="font-size: 10px;">Histogram equalization</a> <a href="/tags/Inception-module/" style="font-size: 10px;">Inception module</a> <a href="/tags/Inception-v3/" style="font-size: 10px;">Inception-v3</a> <a href="/tags/Input-Data/" style="font-size: 10px;">Input Data</a> <a href="/tags/Julia-set/" style="font-size: 10px;">Julia set</a> <a href="/tags/LeNet-5/" style="font-size: 10px;">LeNet-5</a> <a href="/tags/License/" style="font-size: 10px;">License</a> <a href="/tags/Local-Contrast-Normalization/" style="font-size: 10px;">Local Contrast Normalization</a> <a href="/tags/Local-Response-Normalization/" style="font-size: 10px;">Local Response Normalization</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/Network-Structures/" style="font-size: 10px;">Network Structures</a> <a href="/tags/Normalization-Algorithms/" style="font-size: 10px;">Normalization Algorithms</a> <a href="/tags/OpenCL/" style="font-size: 10px;">OpenCL</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/OpenMP/" style="font-size: 10px;">OpenMP</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a> <a href="/tags/Tensorflow/" style="font-size: 10px;">Tensorflow</a> <a href="/tags/Tutorial/" style="font-size: 10px;">Tutorial</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">Currently work for TCL Corporate Research Hong Kong Co., Ltd. Interested in high performance computing and machine learning.</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">yeephycho</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="http://yeephycho.github.io/blog_img/zombie2.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">yeephycho</h1>
			</hgroup>
			
			<p class="header-subtitle">Possibly, yeephycho is a phycho.</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/yeephycho.github.io">Home Page</a></li>
		        
					<li><a href="/archives">All article</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/yeephycho" title="github">github</a>
			        
						<a class="linkedin" target="_blank" href="https://www.linkedin.com/in/%E4%BB%A5%E7%92%87-%E8%83%A1-82ab00102" title="linkedin">linkedin</a>
			        
						<a class="facebook" target="_blank" href="https://www.facebook.com/profile.php?id=100004383827370" title="facebook">facebook</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-II" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/08/02/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-II/" class="article-date">
  	<time datetime="2016-08-02T12:18:33.000Z" itemprop="datePublished">2016-08-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      A note to techniques in Convolutional Neural Networks and their influences II (paper summary)
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BN-Inception/">BN-Inception</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Inception-v3/">Inception-v3</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ResNet/">ResNet</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>If you are not quite familiar with CNN, please view my <a href="http://yeephycho.github.io/2016/07/21/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-I/">previous blog</a> for a better understanding.</p>
<h2 id="BN-Inception"><a href="#BN-Inception" class="headerlink" title="BN-Inception"></a><strong>BN-Inception</strong></h2><p>Related paper is: <a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="external">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>, published on Mar. 2015.</p>
<h3 id="Achievement"><a href="#Achievement" class="headerlink" title="Achievement"></a>Achievement</h3><p>Improved the accuracy of ImageNet 1000 classification, the top-1 and top-5 error rate are 20.1% and 4.9% respectively.<br>Introduced the <a href="">batch normalization</a>, largely reduced the training time cost, for ImageNet classification network, by using batch normalization, can match the same perfomance as the pervious network by only 7% of the training steps.<br>In some cases, time consuming dropout is not quite necessary for the network.<br>Personally, I think that this paper is very important and useful, but it’s not a good paper, because there’s a lot of ambiguous descriptions, some of them are quite contentious. I spent quite a lot of time on it, however, there’s still some details not that clear.<br>The related issue on this paper is based on references and <strong>my personal understanding, if you find any problem, correct me via any means you like please</strong>.<br><a id="more"></a></p>
<h3 id="Internal-Covariate-Shift"><a href="#Internal-Covariate-Shift" class="headerlink" title="Internal Covariate Shift"></a>Internal Covariate Shift</h3><p>In neural network’s training process, different input tranining instances’s data has different distributions, so that the later layers will have to continuously adapt to the new distribution. The input distribution on a learning system changes, it is said to experience <em>covariate shift</em>. You have to use small learning rate as well as initiate the nerwork parameters carefully, the training speed will be quite slow.<br>More over, covariate shift’s bad effect will be more significant as the network structure getting deeper and deeper, because the shift can accumuate.<br>This paper refer to the change in the distributions of internal nodes of a deep network, in the course of training, as <em>Internal Covariate Shift</em>. </p>
<h3 id="Batch-normalization"><a href="#Batch-normalization" class="headerlink" title="Batch normalization"></a>Batch normalization</h3><p>Batch normalization is the most important and complex part of this paper. I think it’s better to introduce this part in <a href="http://yeephycho.github.io/2016/08/03/Normalizations-in-neural-networks/">Normalizations in neural networks</a>.</p>
<h3 id="BN-Inception-architecture"><a href="#BN-Inception-architecture" class="headerlink" title="BN-Inception architecture"></a>BN-Inception architecture</h3><p>BN-Inception is derived from the <a href="http://yeephycho.github.io/2016/07/21/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-I/">GoogLeNet</a> which is also called Inception net, please go to another blog to see the details on the <a href="http://yeephycho.github.io/2016/07/21/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-I/">GoogLeNet</a>. The following content is the difference between the Inception-v2 and GoogLeNet.<br>During the forward training process, after the conv. op., the data will go through the batch normalizaion op. before passing the non-linear activation unit. And the batch normalizaion op. gets involved in the back propagation process also.<br>During the inference process, the used mean for each neural is the average mean of all the batchs for that neural and the variance is the unbiased estimate of the variances of all the batches.<br>The 5x5 conv. layers are replaced by two consecutive 3x3 layers. So, as I mentioned earlier, the depth of the Inception module grows to 3. This modification increases the number of parameters by 25% and the computational cost is increased by about 30%.<br>The number of 28x28 Inception modules is increased from 2 to 3.<br>Inside the Inception modules, the pooling method is not only max-pooling.<br>No across the board pooling layers between andy two Inception modules, but stride-2 conv./pooling layers are employed before the filter concatenations in modules 3c, 4e.<br>The following figure is an illustration of BN-Inception architecture.<div align="center"><br><img src="http://yeephycho.github.io/blog_img/BN_Inception.JPG" alt="BN-Inception architecture"><br></div></p>
<h2 id="Inception-v3"><a href="#Inception-v3" class="headerlink" title="Inception-v3"></a><strong>Inception-v3</strong></h2><p>Related paper is: <a href="https://arxiv.org/pdf/1512.00567v3.pdf" target="_blank" rel="external">Rethinking the Inception Architecture for Computer Vision</a>, published on Dec. 2015.</p>
<h3 id="Achievement-1"><a href="#Achievement-1" class="headerlink" title="Achievement"></a>Achievement</h3><p>Benchmark on ILSVRC 2012 classification challenge validation set, with a single model that has less than 25 million parameters, 5 billion multiply-adds op. (for a single inference), top-5 and top-1 error rate is 5.6% and 21.2%; with an ensemble of 4 models and multi-crop evaluation, reported 3.5% top-5 error rate and 17.3% top-1 error rate.</p>
<h3 id="General-Design-Principles"><a href="#General-Design-Principles" class="headerlink" title="General Design Principles"></a>General Design Principles</h3><p>Four architecture improve skills were raised, these skills are mostly based on the large-scale experimentation with various CNN architectural choices. The author issues to use these ideas judiciously!<br><strong>Avoid representational bottlenecks, especially early in the network.</strong> Down scale the input image and the feature maps gentlely.<br><strong>Higher dimesnisonal representations are easier to process locally within a network.</strong> In a layer of the network, more activations per tile can make it easier to generate more disentangled features. More filters can accelerate training.<br><strong>Spatial aggregation can be done over lower dimensional embeddings without much or any loss in representational power.</strong> So, use dimension reduction generously, it wouldn’t affect too much on your performance if used properly.<br><strong>Balance the width and depth of the network.</strong> Make the computational budget balanced between the deepth and the width of the your network.</p>
<h3 id="Factorizing-Convolutions"><a href="#Factorizing-Convolutions" class="headerlink" title="Factorizing Convolutions"></a>Factorizing Convolutions</h3><p>TBC…</p>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a><strong>ResNet</strong></h2><p>TBC…</p>
<p><br></p>
<h2 id="License"><a href="#License" class="headerlink" title="License"></a>License</h2><div align="center"><br>The content of this blog itself is licensed under the <a href="http://creativecommons.org/licenses/by/4.0/" target="_blank" rel="external">Creative Commons Attribution 4.0 International License</a>.<br><img src="https://raw.githubusercontent.com/yeephycho/yeephycho.github.io/master/blog_img/CC_BY.png" class="[CC_BY_LICENSE]" title="[88] [31] [CC_BY 4.0 [CC_BY 4.0]]"><br><br>The containing source code (if applicable) and the source code used to format and display that content is licensed under the <a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank" rel="external">Apache License 2.0</a>.<br><strong>Copyright [2016] [yeephycho]</strong><br>Licensed under the Apache License, Version 2.0 (the “License”);<br>you may not use this file except in compliance with the License.<br>You may obtain a copy of the License at<br><a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank" rel="external">Apache License 2.0</a><br>Unless required by applicable law or agreed to in writing, software<br>distributed under the License is distributed on an “AS IS” BASIS,<br>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either<br>express or implied. See the License for the specific language<br>governing permissions and limitations under the License.<br><img src="https://raw.githubusercontent.com/yeephycho/yeephycho.github.io/master/blog_img/APACHE.png" class="[APACHE_LICENSE]" title="[120] [48] [APACHE_LICENSE 2.0 [APACHE_LICENSE 2.0]]"><br></div>
      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/08/03/Normalizations-in-neural-networks/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Normalizations in neural networks
        
      </div>
    </a>
  
  
    <a href="/2016/07/21/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-I/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">A note to techniques in Convolutional Neural Networks and their influences I (paper summary)</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>








<section id="comments">
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'yeephycho'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>

</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 yeephycho
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: true
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>



<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-79750926-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
  <script id="dsq-count-scr" src="//yeephycho.disqus.com/count.js#disqus_thread" async></script>
</body>
</html>